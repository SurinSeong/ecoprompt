from contextlib import asynccontextmanager
from fastapi import FastAPI

from app.api.v1.routers import api_router
from app.models.llm_loader import load_llm_engine, llm_engine, load_tokenizer, llm_tokenizer

# lifespan ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì •ì˜
@asynccontextmanager
async def lifespan_manager(app: FastAPI):

    # ğŸš€ ì„œë²„ ì‹œì‘ (Startup) ë¡œì§
    load_tokenizer()    # Tokenizer
    await load_llm_engine()    # LLM ëª¨ë¸ ë¡œë“œ (GPU ë©”ëª¨ë¦¬ ìƒì£¼ ì‹œì‘)
    print("Application startup complete!")

    # yieldê°€ ì‹¤í–‰ë˜ë©´ ì„œë²„ê°€ ìš”ì²­ì„ ë°›ê¸° ì‹œì‘í•¨.
    yield

    # ğŸ›‘ ì„œë²„ ì¢…ë£Œ (Shutdown) ë¡œì§
    if llm_engine is not None:
        pass


# 1. FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI(
    title="Ecoprompt Main LLM",
    description="API Documentation",
    version="1.0.0",
    lifespan=lifespan_manager
)

# 2. ê²½ë¡œ ì‘ë™ í•¨ìˆ˜ (Route Operation) ì •ì˜
@app.get("/")
def read_root():
    """
    HTTP GET ìš”ì²­ì´ ë£¨íŠ¸ ê²½ë¡œ('/')ë¡œ ë“¤ì–´ì™”ì„ ë•Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜
    """
    return {"message": "Hello, FastAPI"}

@app.get("/health")
def health():
    return {"status": "ok"}

# ë¼ìš°í„° ì—°ê²°
app.include_router(api_router, prefix="/api/v1/ai")